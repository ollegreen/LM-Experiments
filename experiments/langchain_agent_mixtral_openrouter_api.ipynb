{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "# sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ollama_model_calls import query_phi, query_solar, query_starling, query_mistral\n",
    "from utils.format_llm_output_text import format_llm_answer\n",
    "from eval.gsm8k_llm import check_answer_using_llm, get_GSM8K_QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPENROUTER_API_KEY = os.environ['OPENROUTER_API_KEY']\n",
    "\n",
    "class ChatOpenRouter(ChatOpenAI):\n",
    "    openai_api_base: str\n",
    "    openai_api_key: str\n",
    "    model_name: str\n",
    "\n",
    "    def __init__(self,\n",
    "                 model_name: str,\n",
    "                 openai_api_key: Optional[str] = None,\n",
    "                 openai_api_base: str = \"https://openrouter.ai/api/v1\",\n",
    "                 **kwargs):\n",
    "        openai_api_key = openai_api_key or os.getenv('OPENROUTER_API_KEY')\n",
    "        super().__init__(openai_api_base=openai_api_base,\n",
    "                         openai_api_key=openai_api_key,\n",
    "                         model_name=model_name, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenRouter(\n",
    "    # model_name=\"mistralai/mistral-7b-instruct:free\",\n",
    "    model_name=\"mistralai/mixtral-8x7b-instruct\",\n",
    "    # model_name=\"fireworks/mixtral-8x22b-instruct-preview\",\n",
    "    # model_name=\"cognitivecomputations/dolphin-mixtral-8x7b\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
    "# openrouter_chain = prompt | llm\n",
    "# print(openrouter_chain.invoke({\"topic\": \"banana\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numexpr as ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def Calculator(expression : str) -> int: # the name of the function takes the place of the name variable.\n",
    "    \"\"\"Use this tool when you need to math. NOTE: this tool uses python numexpr library, so format your input correctly please.\"\"\"\n",
    "    return ne.evaluate(expression).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [Calculator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    k=5,\n",
    "    return_messages=True,\n",
    "    output_key=\"output\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mistral compatability, change depending on LLM\n",
    "\n",
    "# # Openhermes prompt format tokens\n",
    "B_INST, E_INST = \"<|im_start|>user\\n\", \"<|im_end|>\\n\" #Instruction begin and end\n",
    "B_SYS, E_SYS = \"<|im_start|>system\\n\", \"<|im_end|>\\n\" #System message begin and end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = '''Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
    "\n",
    "Valid \"action\" values: \"Final Answer\" or {tool_names}\n",
    "\n",
    "Provide only ONE action per $JSON_BLOB, as shown:\n",
    "\n",
    "```\n",
    "{{\n",
    "  \"action\": $TOOL_NAME,\n",
    "  \"action_input\": $INPUT\n",
    "}}\n",
    "```\n",
    "\n",
    "Follow this format:\n",
    "\n",
    "Question: input question to answer\n",
    "Thought: consider previous and subsequent steps\n",
    "Action:\n",
    "```\n",
    "$JSON_BLOB\n",
    "```\n",
    "Observation: action result\n",
    "... (repeat Thought/Action/Observation N times)\n",
    "Thought: I know what to respond\n",
    "Action:\n",
    "```\n",
    "{{\n",
    "  \"action\": \"Final Answer\",\n",
    "  \"action_input\": \"Final response to human\"\n",
    "}}\n",
    "\n",
    "Begin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation'''\n",
    "\n",
    "# system = B_SYS + '''Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
    "\n",
    "# {tools}\n",
    "\n",
    "# Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
    "\n",
    "# Valid \"action\" values: \"Final Answer\" or {tool_names}\n",
    "\n",
    "# Provide only ONE action per $JSON_BLOB, as shown:\n",
    "\n",
    "# ```\n",
    "# {{\n",
    "#   \"action\": $TOOL_NAME,\n",
    "#   \"action_input\": $INPUT\n",
    "# }}\n",
    "# ```\n",
    "\n",
    "# Follow this format:\n",
    "\n",
    "# Question: input question to answer\n",
    "# Thought: consider previous and subsequent steps\n",
    "# Action:\n",
    "# ```\n",
    "# $JSON_BLOB\n",
    "# ```\n",
    "# Observation: action result\n",
    "# ... (repeat Thought/Action/Observation N times)\n",
    "# Thought: I know what to respond\n",
    "# Action:\n",
    "# ```\n",
    "# {{\n",
    "#   \"action\": \"Final Answer\",\n",
    "#   \"action_input\": \"Final response to human\"\n",
    "# }}\n",
    "\n",
    "# Begin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation''' + E_SYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "human = '''{input}\n",
    "\n",
    "{agent_scratchpad}\n",
    "\n",
    "(reminder to respond in a JSON blob no matter what)'''\n",
    "\n",
    "# human = B_INST + '''\\nUser: {input}\n",
    "\n",
    "# {agent_scratchpad}\n",
    "\n",
    "# (reminder to respond in a JSON blob no matter what)''' + E_INST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        MessagesPlaceholder(\"chat_history\", optional=True),\n",
    "        (\"human\", human),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_structured_chat_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_structured_chat_agent(llm=llm,\n",
    "                                     tools=tools,\n",
    "                                     prompt=prompt,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent,\n",
    "                               tools=tools,\n",
    "                               verbose=True,\n",
    "                               handle_parsing_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Can you tell me what the total money I have if I have earned 544430GBP per day for 530 days?\"\n",
    "# answer = 288'547'900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mQuestion: Can you tell me what the total money I have if I have earned 544430GBP per day for 530 days?\n",
      "Thought: To find the total money earned, I need to multiply the daily earnings by the number of days. I will use the Calculator tool for this calculation.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Calculator\",\n",
      "  \"action_input\": \"544430 * 530\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m288547900\u001b[0m\u001b[32;1m\u001b[1;3m```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"288547900 GBP\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Can you tell me what the total money I have if I have earned 544430GBP per day for 530 days?',\n",
       " 'output': '288547900 GBP'}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numexpr\n",
    "agent_executor.invoke({\"input\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: In order to calculate the WMAPE, I need to find the weighted average of the MAPE of each day. I can calculate this by multiplying the MAPE of each day by the proportion of packages delivered on that day, and then summing those values. To do this, I first need to find the total number of packages delivered over the three days, and then find the proportion of packages delivered on each day.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Calculator\",\n",
      "  \"action_input\": \"20000 + 40000 + 5000\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m65000\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Calculator\",\n",
      "  \"action_input\": \"20000 / 65000 * 20 + 40000 / 65000 * 15 + 5000 / 65000 * 5\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m15.769230769230772\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The WMAPE for these days is approximately 15.77%.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Monday had 20000 packages and a 20% MAPE. Tuesday had 40000 packages and a 15%  MAPE. Wednesday had 5000 packages and a 5% MAPE. What is the WMAPE (weighted average by the package volume) for these days?',\n",
       " 'output': 'The WMAPE for these days is approximately 15.77%.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_context = \"Monday had 20000 packages and a 20% MAPE. Tuesday had 40000 packages and a 15%  MAPE. Wednesday had 5000 packages and a 5% MAPE. \"\n",
    "question = \"What is the WMAPE (weighted average by the package volume) for these days?\"\n",
    "\n",
    "query = email_context + question\n",
    "\n",
    "agent_executor.invoke({\"input\": query})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the answer to  the WAPE question is: 0.1576923076923077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000895"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.000217 + 0.000195 +0.000169 + 0.000165 + 0.000149"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ the cost for running Mixtral this simple calc Q via openrouter: $0.000895 -> $0.001\n",
    "\n",
    "https://openrouter.ai/activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lmx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

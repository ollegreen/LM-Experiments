{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ollama_model_calls import query_phi, query_solar, query_starling, query_mistral_Q\n",
    "from utils.format_llm_output_text import format_llm_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "starling = Ollama(model=\"starling-lm:latest\")\n",
    "solar = Ollama(model=\"solar:10.7b-instruct-v1-q4_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import ArxivQueryRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install arxiv\n",
    "arxiv_query = ArxivQueryRun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "olles_search = \"Language Model Tools\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = arxiv_query.run(olles_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the results:\n",
    "The ArxivQueryRun instance will return a list of dictionaries, where each dictionary represents an arXiv paper and contains metadata about the paper. You can access this information using key-value pairs. For example, you can print out a summary of the search results like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Published: 2023-09-07\n",
       "Title: ToolAlpaca: Generalized Tool Learning for Language Models with 3000 Simulated Cases\n",
       "Authors: Qiaoyu Tang, Ziliang Deng, Hongyu Lin, Xianpei Han, Qiao Liang, Boxi Cao, Le Sun\n",
       "Summary: Enabling large language models to utilize real-world tools effectively is\n",
       "crucial for achieving embodied intelligence. Existing approaches to tool\n",
       "learning have either primarily relied on extremely large language models, such\n",
       "as GPT-4, to attain generalized tool-use abilities in a zero-shot manner, or\n",
       "utilized supervised learning to train limited scopes of tools on compact\n",
       "models. However, it remains uncertain whether smaller language models can\n",
       "achieve generalized tool-use abilities without tool-specific training. To\n",
       "address this question, this paper introduces ToolAlpaca, a novel framework\n",
       "designed to automatically generate a diverse tool-use corpus and learn\n",
       "generalized tool-use abilities on compact language models with minimal human\n",
       "intervention. Specifically, ToolAlpaca first automatically creates a highly\n",
       "diversified tool-use corpus by building a multi-agent simulation environment.\n",
       "The corpus contains 3938 tool-use instances from more than 400 real-world tool\n",
       "APIs spanning 50 distinct categories. Subsequently, the constructed corpus is\n",
       "employed to fine-tune compact language models, resulting in two models, namely\n",
       "ToolAlpaca-7B and ToolAlpaca-13B, respectively. Finally, we evaluate the\n",
       "ability of these models to utilize previously unseen tools without specific\n",
       "training. Experimental results demonstrate that ToolAlpaca achieves effective\n",
       "generalized tool-use capabilities comparable to those of extremely large\n",
       "language models like GPT-3.5, demonstrating that learning generalized tool-use\n",
       "ability is feasible for compact language models.\n",
       "\n",
       "Published: 2019-07-26\n",
       "Title: Simple Natural Language Processing Tools for Danish\n",
       "Authors: Leon Derczynski\n",
       "Summary: This technical note describes a set of baseline tools for automatic\n",
       "processing of Danish text. The tools are machine-learning based, using natural\n",
       "language processing models trained over previously annotated documents. They\n",
       "are maintained at ITU Copenhagen and will always be freely available.\n",
       "\n",
       "Published: 2024-02-10\n",
       "Title: Making Language Models Better Tool Learners with Execution Feedback\n",
       "Authors: Shuofei Qiao, Honghao Gui, Chengfei Lv, Qianghuai Jia, Huajun Chen, Ningyu Zhang\n",
       "Summary: Tools serve as pivotal interfaces that enable humans to understand and\n",
       "reshape the environment. With the advent of foundation models, AI systems can\n",
       "utilize tools to expand their capabilities and interact with the real world.\n",
       "Existing tool learning methodologies, encompassing supervised fine-tuning and\n",
       "prompt engineering approaches, often induce large language models to utilize\n",
       "tools indiscriminately, as complex tasks often exceed their own competencies.\n",
       "However, introducing tools for simple tasks, which the models themselves can\n",
       "readily resolve, can inadvertently propagate errors rather than enhance\n",
       "performance. This leads to the research question: can we teach language models\n",
       "when and how to use tools? To meet this need, we propose Tool leaRning wIth\n",
       "exeCution fEedback (TRICE), a two-stage end-to-end framework that enables the\n",
       "model to continually learn through feedback derived from tool execution,\n",
       "thereby learning when and how to use tools effectively. Experimental results,\n",
       "backed by further analysis, show that TRICE can make the large language model\n",
       "selectively use tools by improving the accuracy of tool usage while enhancing\n",
       "insufficient tool learning and mitigating excessive reliance on tools. Code and\n",
       "datasets are available in https://github.com/zjunlp/trice."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "format_llm_answer(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# for result in results[:10]:  # Printing the first 10 papers\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:  \u001b[38;5;66;03m# check how many I can retrieve\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     paper_id \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43marxivId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m     title \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m     authors \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthors\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "# # for result in results[:10]:  # Printing the first 10 papers\n",
    "# for result in results:  # check how many I can retrieve\n",
    "#     paper_id = result['arxivId']\n",
    "#     title = result['title']\n",
    "#     authors = \", \".join(result['authors'])\n",
    "\n",
    "#     print(f\"\"\"Paper ID: {paper_id}\n",
    "#           Title: {title}\n",
    "#           Authors: {authors}\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def arxiv_query(search_query : str):\n",
    "    \n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_query('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do I want? \n",
    "\n",
    "* **Recent**: Find something that's new.\n",
    "* **High/minimum # of citations**: find something that is prominent and has shown to work in terms of citations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Find relevant paper\n",
    "    * title of paper\n",
    "    * category\n",
    "    * Tags\n",
    "    * Keywords\n",
    "    * date posted\n",
    "2. Is it relevant or good quality?\n",
    "    * reference count\n",
    "    * download count\n",
    "    * author affiliation (companies / unis?)\n",
    "3. Actually retrieve it:\n",
    "    * PDF URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should I make an agent for each?\n",
    "\n",
    "1. The research scientist (agent who argues with itself using ReAct)\n",
    "2. The intern (finding and doing the digging of arxiv using tool and retrievs all the information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Agent, Tool, ZeroShotAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorry currently our systems are down and we cannot retrieve research papers.\n"
     ]
    }
   ],
   "source": [
    "tool = Tool(name=\"scientific_research\",\n",
    "            func=print('sorry currently our systems are down and we cannot retrieve research papers.'),\n",
    "            description=\"use research scientist intern to help retrieve relevant research papers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'llm_chain'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mZeroShotAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstarling\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtool\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lmx/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:180\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     emit_warning()\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lmx/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:180\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     emit_warning()\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lmx/lib/python3.11/site-packages/pydantic/v1/main.py:339\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mCreate a new model by parsing and validating input data from keyword arguments.\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03mRaises ValidationError if the input data cannot be parsed to form a valid model.\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__pydantic_self__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n",
      "File \u001b[0;32m~/miniconda3/envs/lmx/lib/python3.11/site-packages/pydantic/v1/main.py:1102\u001b[0m, in \u001b[0;36mvalidate_model\u001b[0;34m(model, input_data, cls)\u001b[0m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1102\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAssertionError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m   1104\u001b[0m     errors\u001b[38;5;241m.\u001b[39mappend(ErrorWrapper(exc, loc\u001b[38;5;241m=\u001b[39mROOT_KEY))\n",
      "File \u001b[0;32m~/miniconda3/envs/lmx/lib/python3.11/site-packages/langchain/agents/agent.py:739\u001b[0m, in \u001b[0;36mAgent.validate_prompt\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;129m@root_validator\u001b[39m()\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_prompt\u001b[39m(\u001b[38;5;28mcls\u001b[39m, values: Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict:\n\u001b[1;32m    738\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate that prompt matches format.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 739\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllm_chain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mprompt\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent_scratchpad\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m prompt\u001b[38;5;241m.\u001b[39minput_variables:\n\u001b[1;32m    741\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    742\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`agent_scratchpad` should be a variable in prompt.input_variables.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    743\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Did not find it, so adding it at the end.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    744\u001b[0m         )\n",
      "\u001b[0;31mKeyError\u001b[0m: 'llm_chain'"
     ]
    }
   ],
   "source": [
    "agent = ZeroShotAgent(llm=starling, tools=[tool], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lmx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

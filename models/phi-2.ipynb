{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data to test on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/olles/miniconda3/envs/lmx/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSM8K = load_dataset(\"gsm8k\", 'main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_GSM8K_Q(question_or_answer, question_number) -> str:\n",
    "    \n",
    "    if question_or_answer == \"Q\":\n",
    "        output = GSM8K['train']['question'][question_number-1]\n",
    "    elif question_or_answer == \"A\":\n",
    "        output = GSM8K['train']['answer'][question_number-1]\n",
    "    else:\n",
    "        output = \"either put 'Q' for question or 'A' for answer\"\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_GSM8K_Q(\"Q\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# # Check PyTorch has access to MPS (Metal Performance Shader, Apple's GPU architecture)\n",
    "# print(f\"Is MPS (Metal Performance Shader) built? {torch.backends.mps.is_built()}\")\n",
    "# print(f\"Is MPS available? {torch.backends.mps.is_available()}\")\n",
    "\n",
    "# # Set the device\n",
    "# device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "# print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.rand(size=(3, 4)).to(device)\n",
    "# x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phi-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                    \tID          \tSIZE  \tMODIFIED   \n",
      "mistral:7b-instruct-q8_0\t2162e081e7f0\t7.7 GB\t2 days ago\t\n",
      "phi:latest              \te2fd6321a5fe\t1.6 GB\t2 days ago\t\n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"mistral:7b-instruct-q8_0\") # phi / mistral:7b-instruct-q8_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It\\'s difficult for me to say which is the \"best\" country in Scandinavia, as it largely depends on individual preferences and what each person values most. Each of the five countries in Scandinavia - Denmark, Norway, Sweden, Finland, and Iceland - has its own unique culture, attractions, and quality of life. \\n\\nFor example, Denmark is known for its charming cities, world-renowned design, and strong focus on work-life balance. Norway is home to stunning fjords, glaciers, and mountains, as well as a thriving oil industry. Sweden is known for its innovative approach to technology and social equality, while Finland has a rich cultural heritage and beautiful natural landscapes. Iceland is a volcanic island with unique geothermal features, hot springs, and a growing reputation for innovation and entrepreneurship.\\n\\nUltimately, the \"best\" country in Scandinavia will depend on what you value most - whether that\\'s culture, nature, work-life balance, or something else entirely. It might be helpful to research each of these countries more in depth and determine which aligns with your personal preferences the most.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is the best country in Scandinavia if you had to pick one?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_llm(input_query) -> str:\n",
    "    invoke = llm.invoke(input_query)\n",
    "    return invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_llm_answer(llm_output):\n",
    "    formatted_string = llm_output.replace(\"\\\\n\", \"\\n\")\n",
    "    formatted_output = display(Markdown(formatted_string))\n",
    "\n",
    "    return formatted_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I don't have personal preferences. However, I can provide information about any of the Scandinavian countries upon request."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "format_llm_answer(query_llm('What country do you prefer out of the scandinavian countries?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Natalia sold 48 clips in April. In May, she sold half as many clips, which is 24 clips. So, the total number of clips she sold in April and May is:\n",
       "48 + 24 = 72 clips\n",
       "Therefore, Natalia sold a total of 72 clips in April and May."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "format_llm_answer(query_llm(get_GSM8K_Q(\"Q\", 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_GSM8K_Q(\"A\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_answer_from_output(llm_answer, gsm8k_answer):\n",
    "\n",
    "    extract_llm_number = query_llm(f\"What is the final numerical answer of this text: {llm_answer}\")\n",
    "    extract_gsm8k_number = query_llm(f\"What is the final numerical answer of this text: {gsm8k_answer}\")\n",
    "\n",
    "    compare = query_llm(f\"Are these two answers the same: 1; [{extract_llm_number}] and 2; [{extract_gsm8k_number}]\")\n",
    "    compare = query_llm(f\"You are a binary analyser, if the 1; [{extract_llm_number}] and 2; [{extract_gsm8k_number}]\")\n",
    "\n",
    "    print(\"extract_llm_number output: \",extract_llm_number)\n",
    "    print(\"extract_gsm8k_number output: \",extract_gsm8k_number)\n",
    "    print(\"compare output: \",compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract_llm_number output:  The final numerical answer of this text is 72 clips.\n",
      "extract_gsm8k_number output:  The final numerical answer is 72.\n",
      "compare output:  Yes, both answers are equivalent. They both indicate that the final numerical answer is 72. The only difference is in the phrasing and structure of the sentences.\n"
     ]
    }
   ],
   "source": [
    "check_answer_from_output(query_llm(get_GSM8K_Q(\"Q\", 1)), get_GSM8K_Q(\"A\", 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lmx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
